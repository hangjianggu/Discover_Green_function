{
      // Experiment configuration.
   "experiment" : {

         // Root directory to save results.
         "logdir" : "./log/MODE1",
   
         // Random number seed. Don't forget to change this for multiple runs!
         "seed" : 0
      },
   
   "task" : {
      // Deep Symbolic PDE discovery
      "task_type" : "pde",

      // The name of the benchmark dataset (all of the avaiable data provided
      // can be found in ./dso/task/pde/data_new 
      // New dataset can be added according to the application.
      "dataset" : "negative_helmholtz",

      // To customize a function set, edit this! See functions.py for a list of
      // supported funcbatch_tions.
      //      "function_set": ["add", "mul", "sub", "exp", "const", "large", "less"],
//      "function_set": ["add", "mul", "sub", "sinh", "const"],
      "function_set": ["mul", "sub", "sinh", "const"],

      // supported metrics.
      "metric" : "pde_reward",
      "metric_params" : [0.01],

      // Optional alternate metric to be used at evaluation time.
      "extra_metric_test" : null,
      "extra_metric_test_params" : [],

      // threshold for early stopping.
      "threshold" : 5e-4,

      // With protected=false, floating-point errors (e.g. log of negative
      // number) will simply returns a minimal reward. With protected=true,
      // "protected" functions will prevent floating-point errors, but may
      // introduce discontinuities in the learned functions.      
      "protected" : false,

      // You can add artificial reward noise directly to the reward function.
      // Note this does NOT add noise to the dataset.
      "reward_noise" : 0.0,
      "reward_noise_type" : "r",
      "normalize_variance" : false,

      // Set of thresholds (shared by all input variables) for building
      // decision trees. Note that no StateChecker will be added to Library
      // if decision_tree_threshold_set is an empty list or null.
      "decision_tree_threshold_set" : []
   },
   
   // Hyperparameters related to genetic programming hybrid methods.
   "gp_meld" : {
      "run_gp_meld" : false,
      "verbose" : false
      // How many GP generations to run between each RNN step. 
   },

   // Only the key training hyperparameters are listed here. See
   // config_common.json for the full list.
   "training" : {
      "n_samples" : 500000,
      "batch_size" : 500,
      "epsilon" : 0.01,
      // Recommended to set this to as many cores as you can use! Especially if
      // using the "const" token.
      "n_cores_batch" : 1,
      "early_stopping" : false,
      "const_optimizer" : "scipy"
   },

   // Only the key RNN controller hyperparameters are listed here. See
   // config_common.json for the full list.
   "controller" : {
      "learning_rate": 0.0025,
      "entropy_weight" : 0.03,
      "entropy_gamma" : 0.7,
      // Priority queue training hyperparameters.
      "pqt" : true,
      "pqt_k" : 10,
      "pqt_batch_size" : 1,
      "pqt_weight" : 0.0,
      "pqt_use_pg" : true,
      "attention": true
   },

   // Hyperparameters related to including in situ priors and constraints. Each
   // prior must explicitly be turned "on" or it will not be used. See
   // config_common.json for descriptions of each prior.
   "prior": {
      // Memory sanity value. Limit strings to size 256
      // This can be set very high, but it runs slower.
      // Max value is 1000. 
      "length" : {
         "min_" : 3,
         "max_" : 256,
         "on" : true
      },
      // Memory sanity value. Have at most 10 optimizable constants. 
      // This can be set very high, but it runs rather slow. 
      "repeat" : {
         "tokens" : "add",
         "min_" : null,
         "max_" : 10,
         "on" : true
      },
      "inverse" : {
         "on" : true
      },
      "trig" : {
         "on" : true
      },
      "const" : {
         "on" : false
      },
      "no_inputs" : {
         "on" : false
      },
      "uniform_arity" : {
         "on" : false
      },
      "soft_length" : {
         "loc" : 10,
         "scale" : 5,
         "on" : true
      },
      "diff_left":{
         "on":true
      },
      "diff_right":{
         "on":true
      },
      "diff_descedent":{
         "on":true
      },
      "nest_des": {
         "on": true
      }
   }
}
